points(d3,g3,type="l",col="blue")
# Adds in the legend
legend("topright",legend=c("Sub_metering_1","Sub_metering_2","Sub_metering_3"),lty=1,col=c("black","red","blue"))
png("./plot3.png")
png(filename="./plot3.png")
dev.off()
png(filename="./plot3.png")
# Intializes the Plot
plot(d3,g1,xlab="",ylab="Energy sub metering",type="n")
# plots the time series graph for submetering_1
points(d3,g1,type="l",col="black")
# Adding in submetering_2 in red
points(d3,g2,type="l",col="red")
# adding in submetering_3 in blue
points(d3,g3,type="l",col="blue")
# Adds in the legend
legend("topright",legend=c("Sub_metering_1","Sub_metering_2","Sub_metering_3"),lty=1,col=c("black","red","blue"))
dev.off()
plot(a2,type="l",ylab="emissions",main="Total Emissions over Time")
rm(a,d1,d2,a1,a2,b1,b2,c1,c2,d3,d4)
rm(e1,e2,f1,f2,f3,g1,g2,g3,l)
qnorm(0.95,mean=1100,sd=30)
(qnorm(0.95,mean=1100,sd=30)-1100)/3+1100
swirl()
library("swirl")
library("swirl")
swirl()
var(rpois(1000,50))
nxt()
head(hits)
class(hits[,'date'])
as.integer(head(hits[,'data']))
as.integer(head(hits[,'data'])))
as.integer(head(hits[,'date']))
mdl <- glm(visits ~ date, poisson, hits)
summary(mdl)
confint(mdl,'date')
exp(confint(mdl,'date'))
which.max(hits[,'visits'])
hits[704,]
lambda<-mdl$fitted.values[704]
qpois(0.95,lambda)
mdl2<-offset=log(vists+1)
mdl <- glm(visits ~ date, offset=log(visits+1),poisson, hits)
mdl <- glm(visits ~ simplystats+date, offset=log(visits+1),poisson, hits)
mdl <- glm(formula= simplystats~date, offset=log(visits+1),family= poisson, data=hits)
mdl2 <- glm(formula= simplystats~date, offset=log(visits+1),family= poisson, data=hits)
qpois(0.95,mdl2$fitted.values[704])
updateR()
install.packages("quantmod")
install.packages("quandl")
install.packages("Quandl")
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.test
vowel.train
View(vowel.test)
View(vowel.test)
vowel.test[,1]<-as.factor(vowel.test[,1])
vowel.train[,1]<-as.factor(vowel.train[,1])
library(caret)
modfit<-train(y~.,data=vowel.train,method="rf",prox=TRUE)
pred<-predict(modFit,vowel.test)
pred<-predict(modfit,vowel.test)
vowel.testing$predRight<- pred==vowel.testing$y
vowel.testing$predRight<- pred==vowel.test$y
vowel.test$predRight<- pred==vowel.test$y
table(pred,vowel.train$y)
table(pred,vowel.test$y)
library("accuracy")
install.packages("accuracy")
install.packages("forecast")
library("forecast")
accuray(pred,vowel.test$y)
accuracy(pred,vowel.test$y)
dim(pred)
pred
confusionMatrix(pred,vowel.test$y)
sum(as.numeric(vowel.test$predRight))
272/462
vowel.test(,-12)
vowel.test[,-12]
data(vowel.test)
modfit<-train(y~.,data=vowel.train,method="rf")
pred<-predict(modfit,vowel.test)
confusionMatrix(pred,vowel.test$y)
confusionMatrix(pred,vowel.test$y)[[3]][2]
confusionMatrix(pred,vowel.test$y)[[2]][1]
confusionMatrix(pred,vowel.test$y)[[3]][1]
data(vowel.train)
data(vowel.test)
vowel.test[,1]<-as.factor(vowel.test[,1])
vowel.train[,1]<-as.factor(vowel.train[,1])
set.seed(33833)
modfit<-train(y~.,data=vowel.train,method="rf")
pred<-predict(modfit,vowel.test)
#vowel.test$predRight<- pred==vowel.test$y
confusionMatrix(pred,vowel.test$y)
confusionMatrix(pred,vowel.test$y)[[3]][1]
rf_accuracy<-confusionMatrix(pred,vowel.test$y)[[3]][1]
modFit_Boost <- train(y ~ ., method="gbm",data=vowel.train,)
modFit_Boost <- train(y ~ ., method="gbm",data=vowel.train)
modFit_Boost <- train(y ~ ., method="gbm",data=vowel.train)
pred_Boost<-predict(modFit_Boost,vowel.test)
confusionMatrix(pred_Boost,vowel.test$y)[[3]][1]
boost_accuracy<-confusionMatrix(pred_Boost,vowel.test$y)[[3]][1]
predDF<-data.frame(pred,pred_Boost,y=test.vowel$y)
predDF<-data.frame(pred,pred_Boost,y=vowel.test$y)
combModFit<-train(y~.,method="gam",data=predDFl)
combModFit<-train(y~.,method="gam",data=predDF)
combPred <- predict(combModFit,predDF)
accuracy_Combined<-confusionMatrix(combPred,vowel.test$y)[[3]][1]
confusionMatrix(combPred,vowel.test$y)[[3]][1]
sqrt(sum((combPred-vowel.test$y)^2))
keep<-apply(predDF,1,function(x) any(x %in% in 1:2))
keep<-apply(predDF,1,function(x) any(x %in% 1:2))
pred_Both<-predDF[keep]
pred_Both<-predDF[keep,]
View(pred_Both)
pred_Both<-predDF[!keep,]
View(pred_Both)
View(pred_Both)
both_accuracy<-confusionMatrix(pred_Both$pred,predLDF$y)
both_accuracy<-confusionMatrix(pred_Both$pred,predDF$y)[[2]][1]
both_accuracy<-confusionMatrix(pred_Both$pred,pred_Both$y)[[2]][1]
confusionMatrix(pred_Both$pred,pred_Both$y)[[2]][1]
correct<-lapply(pred_Both,1,function(x) any(x %in% 2:3))
correct<-apply(pred_Both,1,function(x) any(x %in% 2:3))
class(correct)
sum(as.numeric(correct))/length(correct)
correct
correct<-apply(pred_Both,1,function(x) any(x %in% 2:3))
dim(correct)
correct
dim(pre_Both)
View(pred_Both)
correct<-apply(pred_Both[,c('pred','y')],1,function(x) if(x[1]=x[2]{1}))
correct<-apply(pred_Both[,c('pred','y')],1,function(x) if(x[1]==x[2]){1}))
correct<-apply(pred_Both[,c('pred','y')],1,function(x) if(x[1]==x[2]){1})
sum(correct)
correct<-as.vector(apply(pred_Both[,c('pred','y')],1,function(x) if(x[1]==x[2]){1}))
correct<-as.vector(apply(pred_Both[,c('pred','y')],1,function(x) if(x[1]==x[2]){1}))
class(correct)
correct<-as.data.frame(apply(pred_Both[,c('pred','y')],1,function(x) if(x[1]==x[2]){1}else{0}))
accuracy_both=sum(correct)/length(correct)
View(correct)
accuracy_both=sum(correct[,1\])/length(correct)
accuracy_both=sum(correct[,1])/length(correct)
correct[,1]
sum(correct[,1])
lenght(correct)
length(correct)
dim(correct)
218/345
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
View(training)
modFit_rf <- train(diagnosis ~ ., method="rf",data=training)
modFit_gbm <- train(diagnosis ~ ., method="gbm",data=training)
modFit_lda <- train(diagnosis ~ ., method="lda",data=training)
pred_rf<-predict(model_rf,testing)
pred_gbm<-predict(modFit_gbm,testing)
modFit_lda<-predict(modLFit_lda,testing)
pred_rf<-predict(modFit_rf,testing)
pred_gbm<-predict(modFit_gbm,testing)
modFit_da<-predict(modFit_lda,testing)
accuracy_rf<-confusionMatrix(pred_rf,training$diagnosis)[[3]][1]
accuracy_rf<-confusionMatrix(pred_rf,testing$diagnosis)[[3]][1]
accuracy_gbm<-confusionMatrix(pred_gbm,testing$diagnosis)[[3]][1]
accuracy_lda<-confusionMatrix(pred_lda,testing$diagnosis)[[3]][1]
pred_lda<-predict(modFit_lda,testing)
accuracy_lda<-confusionMatrix(pred_lda,testing$diagnosis)[[3]][1]
train_rf<-predict(modFit_rf,training)
train_gbm<-predict(modFit_gbm,training)
train_lda<-predict(modFit_lda,training)
test_stacked<-data.frame(train_rf,train_gbm,train_lda,train$diagnosis)
test_stacked<-data.frame(train_rf,train_gbm,train_lda,training$diagnosis)
View(test_stacked)
modFit_Stacked<-train(training.diagnosis~.,method="rf",data=test_stacked)
pred_Stacked<-predict(modFit_Stacked,testing)
accuracy_Stacked<-confusionMatrix(pred_Stacked,testing$diagnosis)[[3]][1]
pred_Stacked
modFit_Stacked<-train(diagnosis~.,method="rf",data=test_stacked)
test_stacked<-data.frame(train_rf,train_gbm,train_lda,diagnosis=training$diagnosis)
modFit_Stacked<-train(diagnosis~.,method="rf",data=test_stacked)
pred_Stacked<-predict(modFit_Stacked,test_stacked)
accuracy_Stacked<-confusionMatrix(pred_Stacked,testing$diagnosis)[[3]][1]
accuracy_Stacked<-confusionMatrix(pred_Stacked,test_stacked$diagnosis)[[3]][1]
confusionMatrix(pred_Stacked,test_stacked$diagnosis)
test_stacked<-data.frame(pred_rf,pred_gbm,pred_lda,diagnosis=testing$diagnosis)
modFit_Stacked<-train(diagnosis~.,method="rf",data=test_stacked)
pred_Stacked<-predict(modFit_Stacked,test_stacked)
accuracy_Stacked<-confusionMatrix(pred_Stacked,test_stacked$diagnosis)[[3]][1]
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
modFit_rf <- train(diagnosis ~ ., method="rf",data=training)
modFit_gbm <- train(diagnosis ~ ., method="gbm",data=training)
modFit_lda <- train(diagnosis ~ ., method="lda",data=training)
pred_rf<-predict(modFit_rf,testing)
pred_gbm<-predict(modFit_gbm,testing)
pred_lda<-predict(modFit_lda,testing)
accuracy_rf<-confusionMatrix(pred_rf,testing$diagnosis)[[3]][1]
accuracy_gbm<-confusionMatrix(pred_gbm,testing$diagnosis)[[3]][1]
accuracy_lda<-confusionMatrix(pred_lda,testing$diagnosis)[[3]][1]
test_stacked<-data.frame(pred_rf,pred_gbm,pred_lda,diagnosis=testing$diagnosis)
modFit_Stacked<-train(diagnosis~.,method="rf",data=test_stacked)
pred_Stacked<-predict(modFit_Stacked,test_stacked)
accuracy_Stacked<-confusionMatrix(pred_Stacked,test_stacked$diagnosis)[[3]][1]
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
View(training)
modelFit<-train(CompressiveStrength~., method="lasso",data=training)
modelFit<-train(CompressiveStrength~., method="lasso",data=training)
?plot.lenet
?plot.enet
plot(modelFit)
modelFit$finalModel
plot.enet(fit_lasso$finalllModel,xvar=c("penalty"),use.color=TRUE)
plot.enet(modelFit$finalModel,xvar=c("penalty"),use.color=TRUE)
plot.enet(modelFit$finalModel,use.color=TRUE)
plot.enet(modelFit$finalModel,xvar=c("penalty"),use.color=TRUE)
plot.enet(modelFit$finalModel,xvar=c("penalty"),use.color=TRUE,legend=names(training))
names(training)
warnings()
b<-modelFit$finalModel
plot.enet(modelFit$finalModel,xvar=c("penalty"),use.color=FALSE)
plot.enet(modelFit$finalModel,xvar=c("penalty"),use.color=TRUE)
library(lubridate)  # For year() function below
dat = read.csv("~/Desktop/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv")
getwd()
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv","q5.csv")
library(lubridate)  # For year() function below
dat = read.csv("~/gaData.csv")
install.packages("lubridate")
library("lubridate")
dat = read.csv("~/q5.csv")
dat = read.csv("c:/R/q5.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
tstrain
dat = read.csv("c:/R/q5.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
View(testing)
model_fit<-bats(training$date,training$visitsTumblr)
model_fit<-bats(training)
model_fit<-bats(training$date)
plot(forecast(model_fit))
model_fit(tstrain)
model_fit=bats(tstrain)
tstest<-ts(testing#visitsTumblr)
model_fit(tstrain)
tstrain = ts(training$visitsTumblr)
a<-forecast(tstrain)
plot(a)
library(lubridate)  # For year() function below
dat = read.csv("c:/R/q5.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
model_fit<-bats(testing)
View(training)
model_fit<-bats(tstrain)
forcast<-forecast(model_fit)
plot(florcast)
plot(forcast)
lines(testing,col="red")
View(testing)
plot(forcast,xlim=(350,600))
plot(forcast,xlim=c(350,600))
lines(testing,col="red")
lines(testing,col="red",type="o")
View(training)
View(dat)
dat<-dat[,2:3]
View(dat)
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
model_fit<-bats(tstrain)
forcast<-forecast(model_fit)
plot(forcast)
lines(testing,col="red")
values<-plot(forcast)
values[[1]]
values[[2]]
values[[3]]
forcast
forcast<-forecast(model_fit,h=235)
plot(forcast)
forecast[9]
forecast[[9]]
forecast
forcast[[9]]
forcast
a<-forcast[1]
a<-forcast[[1]
]
forcast[[1]]
forcast[[2]]
forcast[[3]]
forcast[[4]]
forcast[[5]]
forcast
forcast[[6]]
forcast
forcast[[6]][2]
forcast[[6]
]
class(forcast[[6]])
dim(forcast[[6]])
forcast[[6]][,2]
max<-forcast[[5]]
min<-forcast[[6]][,2]
lines(testing,col="red")
range_1<-data.frame(min,max,testing$visitsTumblr)
View(range_1)
View(max)
forecast
forcast
max<-forcast[[5]][,2]
range_1<-data.frame(min,max,testing$visitsTumblr)
output<-apply(range_1,1,function(x) if(range_1[,3]<range_1[,2]&&range_1[,3]>range_1[,1]))
output<-apply(range_1,1,function(x) if(range_1[,3]<range_1[,2]&&range_1[,3]>range_1[,1]){1})
dim(Output,2)
dim(output,2)
dim()dim(output)[2]
dim(output)[2]
dim(output)[1]
dim(output)
length(output)
Out_bounds=sum(output)/length(output)
View(range_1)
output<-apply(range_1,1,function(x) if(x[,3]<x[,2]&&x[,3]>x[,1]){1})
output<-apply(range_1,1,function(range_1) if(x[,3]<x[,2]&&x[,3]>x[,1]){1})
output<-apply(range_1,1,function(range_1) if(range_1[,3]<range_1[,2]&&x[,3]>range_1[,1]){1})
output<-apply(range_1,1,function(x) if(x[,3]<x[,2]&&x[,3]>x[,1]){1}else{0})
output<-apply(range_1,1,function(x) if(x[3]<x[2]&&x[3]>x[1]){1}else{0})
In_bounds=sum(output)/length(output)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
install.packages("e1071")
install.packages("e1071")
library(e1071)
View(training)
svm(CompressiveStrength~.,data=training)
model_fit<-svm(CompressiveStrength~.,data=training)
pred<-pred(model_fit,testing)
pred<-predict(model_fit,testing)
View(testing)
sqrt((testing$CompressiveStrength-pred)^2)
sum(sqrt((testing$CompressiveStrength-pred)^2))
sum(sqrt((testing$CompressiveStrength-pred)^2))/count(predict)
sum(sqrt((testing$CompressiveStrength-pred)^2))/length(pred)
rmse(pred,testing$CompressiveStrength)
install.packages("hydroGOF")
library(hydroGOF
)
rmse(pred,testing$CompressiveStrength)
install.packages("devtools")
install_github("ramnathv/rCharts@dev")
library(devtools)
install_github("ramnathv/rCharts@dev")
?summary
help(summary)
man(summary)
?summary()
install.packages("rCharts")
install_github("ramnathv/rCharts")
library("rcharts")
library("rCharts")
setwd("./s9p1")
library(shiny)
library(shinyapps)
deployApp()
install.packages("rstudio")
deployApp()\
deployApp()
deployApp()
runApp()
deployApp()
library(slidify)
author(test)
author('test')
slidify('index.Rmd')
library(knitr)
browseURL('index.html')
browseURL('index.html')
slidify('index.Rmd')
browseURL('index.html')
browseURL('index.html')
slidify('index.Rmd')
browseURL('index.html')
slidify('index.Rmd')
slidify('index.Rmd')
browseURL('index.html')
slidify('index.Rmd')
slidify('index.Rmd')
browseURL('index.html')
slidify('index.Rmd')
browseURL('index.html')
slidify('index.Rmd')
browseURL('index.html')
slidify('index.Rmd')
browseURL('index.html')
slidify('index.Rmd')
browseURL('index.html')
slidify('index.Rmd')
browseURL('index.html')
slidify('index.Rmd')
browseURL('index.html')
slidify('index.Rmd')
browseURL('index.html')
slidify('index.Rmd')
browseURL('index.html')
slidify('index.Rmd')
browseURL('index.html')
slidify('index.Rmd')
browseURL('index.html')
slidify('index.Rmd')
browseURL('index.html')
slidify('index.Rmd')
browseURL('index.html')
slidify('index.Rmd')
browseURL('index.html')
slidify('index.Rmd')
browseURL('index.html')
slidify('index.Rmd')
browseURL('index.html')
slidify('index.Rmd')
browseURL('index.html')
slidify('index.Rmd')
browseURL('index.html')
slidify('index.Rmd')
browseURL('index.html')
slidify('index.Rmd')
browseURL('index.html')
slidify('index.Rmd')
browseURL('index.html')
slidify('index.Rmd')
browseURL('index.html')
slidify('index.Rmd')
browseURL('index.html')
slidify('index.Rmd')
browseURL('index.html')
slidify('index.Rmd')
browseURL('index.html')
slidify('index.Rmd')
browseURL('index.html')
slidify('index.Rmd')
browseURL('index.html')
slidify('index.Rmd')
browseURL('index.html')
slidify('index.Rmd')
browseURL('index.html')
slidify('index.Rmd')
browseURL('index.html')
slidify('index.Rmd')
browseURL('index.html')
slidify('index.Rmd')
browseURL('index.html')
slidify('index.Rmd')
browseURL('index.html')
slidify('index.Rmd')
browseURL('index.html')
publish_github(blakea83,Class-9-Project-1)
slidify('index.Rmd')
browseURL('index.html')
RAS+Q=1
slidify('index.Rmd')
browseURL('index.html')
slidify('index.Rmd')
browseURL('index.html')
slidify('index.Rmd')
browseURL('index.html')
browseURL('index.html')
slidify('index.Rmd')
browseURL('index.html')
publish(title = 'State_Point_Presentation', 'index.html', host = 'rpubs')
